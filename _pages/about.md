---
permalink: /
title: ""
excerpt: ""
author_profile: true
redirect_from: 
  - /about/
  - /about.html
---

{% if site.google_scholar_stats_use_cdn %}
{% assign gsDataBaseUrl = "https://cdn.jsdelivr.net/gh/" | append: site.repository | append: "@" %}
{% else %}
{% assign gsDataBaseUrl = "https://raw.githubusercontent.com/" | append: site.repository | append: "/" %}
{% endif %}
{% assign url = gsDataBaseUrl | append: "google-scholar-stats/gs_data_shieldsio.json" %}

<span class='anchor' id='about-me'></span>

# ğŸ™‚ About Me
Hello! I'm Qihao, a second year master's student in the School of Computer Science at South China Normal Universty, advised by Professor [Tinyong Hao](https://scholar.google.com/citations?user=gM77jOQAAAAJ) and supported by the [TAM Lab](https://tony-hao.github.io/TAMLab/index.html). 

My research interests include multimodal representation learning, natural language processing, multilingual lexical semantics, large language/vision-language models. See my Publications (mostly up to date) or [Google Scholar](https://scholar.google.com.hk/citations?user=rNsndk0AAAAJ) page for papers and more information.

I am a travel enthusiast. In the past two years, I have been to Shanghai, Hangzhou, Changsha, Xiangxi Tujia and Miao Autonomous Prefecture, Wuhan, Chaohu, Huangshan, Chengdu, Dujiangyan, Aba Tibetan Autonomous Prefecture, Tianjin, Beijing, Macau, Hong Kong, and Seoul. Traveling around the world is one of my dreams.

I am also one of the founders of LingX, an Empirical Linguistics Studio (è¯­è¨€å­¦å®è¯æ€è¾¨åŠ) that aims to deliver consulting and methods related to quantitative linguistics and computational linguistics. The studio has designed and launched a course titled Text Mining and Python Programming and has organized online academic training sessions, attended by over 400 teachers and students from various universities. I am the principal instructor for the course.

Currently, I am pursuing a PhD opportunity for Fall 2025. I hope to further delve into research on practical multimodal applications, large multilingual/vision-language models.

# ğŸ”¥ News
- *2024.05.30*: &nbsp;ğŸ‰ğŸ‰ I will be joining [The Education University of Hong Kong](https://www.eduhk.hk/en/) as a 6-month research assistant from summer 2024, co-advised by Professor [Guandong Xu](https://repository.eduhk.hk/en/persons/guandong%E5%BE%90%E8%B2%AB%E6%9D%B1-xu). I would like to thank Professor Tianyong Hao for granting me the opportunity to go abroad for exchange!
- *2024.05.27*: &nbsp;ğŸ‰ğŸ‰ I am granted a project supported by the Scientific Research Innovation Project of Graduate School of South China Normal University. It earned me an honor!
- *2024.05.15*: &nbsp;ğŸ‰ğŸ‰ A paper is accepted by [ACL2024](https://2024.aclweb.org/) main conference! See you in Bangkok!
- *2024.04.15*: &nbsp;ğŸ‰ğŸ‰ I have arrived in Seoul, South Korea. And I am going to attend the [ICASSP2024](https://2024.ieeeicassp.org/) conference. Let's have a wonderful encounter!
- *2024.04.01*: &nbsp;ğŸ‰ğŸ‰ I pass the interview with the [TsinghuaNLP Lab](https://nlp.csai.tsinghua.edu.cn/) and establish a scientific research collaboration with the excellent researchers from Tsinghua University!

# ğŸ“ Publications 

<div class='paper-box'><div class='paper-box-image'><div><div class="badge">ACL 2024 Main</div><img src='images/ACL2024_MODEL.png' alt="sym" width="100%"></div></div>
<div class='paper-box-text' markdown="1">

[PolCLIP: A Unified Image-Text Word Sense Disambiguation Model via Generating Multimodal Complementary Representations](https://openreview.net/forum?id=reddQnmur6)

**Qihao Yang**, Yong Li, Xuelin Wang, Fu Lee Wang (Hong Kong), Tianyong Hao*(corresponding author)

**Key words** <strong><span class='show_paper_citations' data='DhtAFkwAAAAJ:ALROH1vI_8AC'></span></strong>
- Word Sense Disambiguation, Contrastive Learning, Multimodal Learning.

**TL;DR** <strong><span class='show_paper_citations' data='DhtAFkwAAAAJ:ALROH1vI_8AC'></span></strong>
- This paper proposes a unified image-text word sense disambiguation model, achieving the state-of-the-art results on both Textual-WSD and Visual-WSD.

**Project** <strong><span class='show_paper_citations' data='DhtAFkwAAAAJ:ALROH1vI_8AC'></span></strong>
- Supported by the Scientific Research Innovation Project of Graduate School of South China Normal University (Grant No. 2024KYLX090). 
</div>
</div>

<div class='paper-box'><div class='paper-box-image'><div><div class="badge">ICASSP 2024 Main</div><img src='images/ICASSP2024_MODEL.png' alt="sym" width="100%"></div></div>
<div class='paper-box-text' markdown="1">

[MTA: A Lightweight Multilingual Text Alignment Model for Cross-Language Visual Word Sense Disambiguation](https://ieeexplore.ieee.org/abstract/document/10447455)

**Qihao Yang**, Xuelin Wang, Yong Li, Lap-Kei Lee (Hong Kong), Fu Lee Wang (Hong Kong), Tianyong Hao*(corresponding author)

**Key words** <strong><span class='show_paper_citations' data='DhtAFkwAAAAJ:ALROH1vI_8AC'></span></strong>
- Visual Word Sense Disambiguation, Image-Text Retrieval, Multimodal Learning, Cross-lingual.

**TL;DR** <strong><span class='show_paper_citations' data='DhtAFkwAAAAJ:ALROH1vI_8AC'></span></strong>
- This paper proposes a lightweight text alignment model for visual word sense disambiguation.
</div>
</div>

# ğŸ– Honors and Awards
- *2021.10* Lorem ipsum dolor sit amet, consectetur adipiscing elit. Vivamus ornare aliquet ipsum, ac tempus justo dapibus sit amet. 
- *2021.09* Lorem ipsum dolor sit amet, consectetur adipiscing elit. Vivamus ornare aliquet ipsum, ac tempus justo dapibus sit amet. 

# ğŸ“– Educations
- *2019.06 - 2022.04 (now)*, Lorem ipsum dolor sit amet, consectetur adipiscing elit. Vivamus ornare aliquet ipsum, ac tempus justo dapibus sit amet. 
- *2015.09 - 2019.06*, Lorem ipsum dolor sit amet, consectetur adipiscing elit. Vivamus ornare aliquet ipsum, ac tempus justo dapibus sit amet. 

# ğŸ’¬ Invited Talks
- *2021.06*, Lorem ipsum dolor sit amet, consectetur adipiscing elit. Vivamus ornare aliquet ipsum, ac tempus justo dapibus sit amet. 
- *2021.03*, Lorem ipsum dolor sit amet, consectetur adipiscing elit. Vivamus ornare aliquet ipsum, ac tempus justo dapibus sit amet.  \| [\[video\]](https://github.com/)

<!-- 
# ğŸ’» Internships
- *2019.05 - 2020.02*, [Lorem](https://github.com/), China. 
-->
